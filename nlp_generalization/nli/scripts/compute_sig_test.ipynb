{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats as stats\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict as ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../out_files/nli_dict.pkl', 'rb') as wf:\n",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nli_dict.pkl', 'rb') as wf:\n",
    "    nli_dict = pickle.load(wf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snli', 'mnli', 'snli-cf', 'conjnli', 'matmnli', 'hans', 'taxinli', 'snli-bt', 'pmonli', 'nmonli']\n",
      "['bertbc-adapter-895K', 'bertbc-lora-592K', 'bertbc-plain', 'bertlc-adapter-3.17M', 'bertlc-lora-1.58M', 'bertlc-plain', 'optb-lora-1.57M', 'optb-plain', 'optl-lora-3.15M', 'optl-plain', 'rb-adapter-895K', 'rb-lora-1.18M', 'rb-plain', 'rl-adapter-3.17M', 'rl-lora-2.63M', 'rl-plain', 't5b-adapter-1.79M', 't5b-lora-1.77M', 't5b-plain', 't5l-adapter-6.34M', 't5l-lora-4.72M', 't5l-plain']\n"
     ]
    }
   ],
   "source": [
    "datasets= list(nli_dict.keys())\n",
    "models  = list(nli_dict['snli'].keys())\n",
    "\n",
    "print(datasets)\n",
    "print(sorted(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
      "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
      " (0 - 1)      0.075     0.000     0.067     0.082\n",
      " (0 - 2)      0.043     0.000     0.035     0.051\n",
      " (0 - 3)      0.030     0.000     0.022     0.038\n",
      " (0 - 4)      0.040     0.000     0.032     0.048\n",
      " (0 - 5)      0.012     0.000     0.004     0.019\n",
      " (0 - 6)      0.090     0.000     0.082     0.098\n",
      " (0 - 7)      0.021     0.000     0.013     0.029\n",
      " (1 - 0)     -0.075     0.000    -0.082    -0.067\n",
      " (1 - 2)     -0.032     0.000    -0.039    -0.024\n",
      " (1 - 3)     -0.045     0.000    -0.053    -0.037\n",
      " (1 - 4)     -0.035     0.000    -0.043    -0.027\n",
      " (1 - 5)     -0.063     0.000    -0.071    -0.055\n",
      " (1 - 6)      0.016     0.000     0.008     0.024\n",
      " (1 - 7)     -0.054     0.000    -0.062    -0.046\n",
      " (2 - 0)     -0.043     0.000    -0.051    -0.035\n",
      " (2 - 1)      0.032     0.000     0.024     0.039\n",
      " (2 - 3)     -0.013     0.000    -0.021    -0.005\n",
      " (2 - 4)     -0.003     0.906    -0.011     0.005\n",
      " (2 - 5)     -0.031     0.000    -0.039    -0.024\n",
      " (2 - 6)      0.047     0.000     0.039     0.055\n",
      " (2 - 7)     -0.022     0.000    -0.030    -0.014\n",
      " (3 - 0)     -0.030     0.000    -0.038    -0.022\n",
      " (3 - 1)      0.045     0.000     0.037     0.053\n",
      " (3 - 2)      0.013     0.000     0.005     0.021\n",
      " (3 - 4)      0.010     0.004     0.002     0.018\n",
      " (3 - 5)     -0.018     0.000    -0.026    -0.010\n",
      " (3 - 6)      0.060     0.000     0.053     0.068\n",
      " (3 - 7)     -0.009     0.015    -0.017    -0.001\n",
      " (4 - 0)     -0.040     0.000    -0.048    -0.032\n",
      " (4 - 1)      0.035     0.000     0.027     0.043\n",
      " (4 - 2)      0.003     0.906    -0.005     0.011\n",
      " (4 - 3)     -0.010     0.004    -0.018    -0.002\n",
      " (4 - 5)     -0.028     0.000    -0.036    -0.020\n",
      " (4 - 6)      0.051     0.000     0.043     0.058\n",
      " (4 - 7)     -0.019     0.000    -0.027    -0.011\n",
      " (5 - 0)     -0.012     0.000    -0.019    -0.004\n",
      " (5 - 1)      0.063     0.000     0.055     0.071\n",
      " (5 - 2)      0.031     0.000     0.024     0.039\n",
      " (5 - 3)      0.018     0.000     0.010     0.026\n",
      " (5 - 4)      0.028     0.000     0.020     0.036\n",
      " (5 - 6)      0.079     0.000     0.071     0.087\n",
      " (5 - 7)      0.009     0.007     0.002     0.017\n",
      " (6 - 0)     -0.090     0.000    -0.098    -0.082\n",
      " (6 - 1)     -0.016     0.000    -0.024    -0.008\n",
      " (6 - 2)     -0.047     0.000    -0.055    -0.039\n",
      " (6 - 3)     -0.060     0.000    -0.068    -0.053\n",
      " (6 - 4)     -0.051     0.000    -0.058    -0.043\n",
      " (6 - 5)     -0.079     0.000    -0.087    -0.071\n",
      " (6 - 7)     -0.069     0.000    -0.077    -0.061\n",
      " (7 - 0)     -0.021     0.000    -0.029    -0.013\n",
      " (7 - 1)      0.054     0.000     0.046     0.062\n",
      " (7 - 2)      0.022     0.000     0.014     0.030\n",
      " (7 - 3)      0.009     0.015     0.001     0.017\n",
      " (7 - 4)      0.019     0.000     0.011     0.027\n",
      " (7 - 5)     -0.009     0.007    -0.017    -0.002\n",
      " (7 - 6)      0.069     0.000     0.061     0.077\n",
      "\n",
      "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
      "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
      " (0 - 1)      0.163     0.000     0.153     0.173\n",
      " (0 - 2)      0.084     0.000     0.074     0.094\n",
      " (0 - 3)      0.114     0.000     0.104     0.125\n",
      " (0 - 4)      0.040     0.000     0.029     0.050\n",
      " (0 - 5)      0.044     0.000     0.034     0.055\n",
      " (0 - 6)      0.194     0.000     0.183     0.204\n",
      " (0 - 7)     -0.032     0.000    -0.042    -0.022\n",
      " (1 - 0)     -0.163     0.000    -0.173    -0.153\n",
      " (1 - 2)     -0.079     0.000    -0.089    -0.069\n",
      " (1 - 3)     -0.048     0.000    -0.059    -0.038\n",
      " (1 - 4)     -0.123     0.000    -0.133    -0.113\n",
      " (1 - 5)     -0.119     0.000    -0.129    -0.108\n",
      " (1 - 6)      0.031     0.000     0.020     0.041\n",
      " (1 - 7)     -0.195     0.000    -0.205    -0.185\n",
      " (2 - 0)     -0.084     0.000    -0.094    -0.074\n",
      " (2 - 1)      0.079     0.000     0.069     0.089\n",
      " (2 - 3)      0.031     0.000     0.020     0.041\n",
      " (2 - 4)     -0.044     0.000    -0.054    -0.034\n",
      " (2 - 5)     -0.040     0.000    -0.050    -0.029\n",
      " (2 - 6)      0.110     0.000     0.099     0.120\n",
      " (2 - 7)     -0.116     0.000    -0.126    -0.106\n",
      " (3 - 0)     -0.114     0.000    -0.125    -0.104\n",
      " (3 - 1)      0.048     0.000     0.038     0.059\n",
      " (3 - 2)     -0.031     0.000    -0.041    -0.020\n",
      " (3 - 4)     -0.075     0.000    -0.085    -0.064\n",
      " (3 - 5)     -0.070     0.000    -0.081    -0.060\n",
      " (3 - 6)      0.079     0.000     0.069     0.090\n",
      " (3 - 7)     -0.146     0.000    -0.157    -0.136\n",
      " (4 - 0)     -0.040     0.000    -0.050    -0.029\n",
      " (4 - 1)      0.123     0.000     0.113     0.133\n",
      " (4 - 2)      0.044     0.000     0.034     0.054\n",
      " (4 - 3)      0.075     0.000     0.064     0.085\n",
      " (4 - 5)      0.004     0.908    -0.006     0.015\n",
      " (4 - 6)      0.154     0.000     0.143     0.164\n",
      " (4 - 7)     -0.072     0.000    -0.082    -0.061\n",
      " (5 - 0)     -0.044     0.000    -0.055    -0.034\n",
      " (5 - 1)      0.119     0.000     0.108     0.129\n",
      " (5 - 2)      0.040     0.000     0.029     0.050\n",
      " (5 - 3)      0.070     0.000     0.060     0.081\n",
      " (5 - 4)     -0.004     0.908    -0.015     0.006\n",
      " (5 - 6)      0.149     0.000     0.139     0.160\n",
      " (5 - 7)     -0.076     0.000    -0.087    -0.066\n",
      " (6 - 0)     -0.194     0.000    -0.204    -0.183\n",
      " (6 - 1)     -0.031     0.000    -0.041    -0.020\n",
      " (6 - 2)     -0.110     0.000    -0.120    -0.099\n",
      " (6 - 3)     -0.079     0.000    -0.090    -0.069\n",
      " (6 - 4)     -0.154     0.000    -0.164    -0.143\n",
      " (6 - 5)     -0.149     0.000    -0.160    -0.139\n",
      " (6 - 7)     -0.226     0.000    -0.236    -0.215\n",
      " (7 - 0)      0.032     0.000     0.022     0.042\n",
      " (7 - 1)      0.195     0.000     0.185     0.205\n",
      " (7 - 2)      0.116     0.000     0.106     0.126\n",
      " (7 - 3)      0.146     0.000     0.136     0.157\n",
      " (7 - 4)      0.072     0.000     0.061     0.082\n",
      " (7 - 5)      0.076     0.000     0.066     0.087\n",
      " (7 - 6)      0.226     0.000     0.215     0.236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### perform the Tukeys' HSD test to validate whether the model is significantly different from the others\n",
    "\n",
    "for dataset in datasets[0:2]:\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    for model in models:\n",
    "        pred_A =  list(nli_dict[dataset][model]['predictions'])\n",
    "        gold_A =  list(nli_dict[dataset][model]['label'])\n",
    "        pred_A = [1 if pred_A[i] == gold_A[i] else 0 for i in range(len(pred_A))]\n",
    "        predictions.append(pred_A)\n",
    "        \n",
    "\n",
    "    res = stats.tukey_hsd(predictions[0], predictions[1], predictions[2], predictions[3], \\\n",
    "        predictions[4], predictions[5], predictions[6], predictions[7])\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rl-plain', 'bertbc-adapter-895K', 'rb-adapter-895K', 'optb-plain', 't5b-adapter-1.79M', 'rb-plain', 'optl-lora-3.15M', 't5l-lora-4.72M', 't5l-adapter-6.34M', 'optl-plain', 'rl-adapter-3.17M', 'bertlc-plain', 'optb-lora-1.57M', 'rb-lora-1.18M', 't5b-lora-1.77M', 'rl-lora-2.63M', 'bertlc-adapter-3.17M', 'bertbc-lora-592K', 't5l-plain', 'bertbc-plain', 't5b-plain', 'bertlc-lora-1.58M'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### observe only on the snli dataset\n",
    "nli_dict['snli'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['t5b-plain', 'rl-plain',  'rb-lora-1.18M', 'rb-adapter-895K']\n",
    "dataset = 'snli'\n",
    "model_A = 'rb-plain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_A</th>\n",
       "      <th>model_B</th>\n",
       "      <th>mean_A</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>std_A</th>\n",
       "      <th>std_B</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>t5b-plain</td>\n",
       "      <td>0.914393</td>\n",
       "      <td>0.897258</td>\n",
       "      <td>0.279782</td>\n",
       "      <td>0.303621</td>\n",
       "      <td>7.124641</td>\n",
       "      <td>5.277183e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>rl-plain</td>\n",
       "      <td>0.914393</td>\n",
       "      <td>0.925998</td>\n",
       "      <td>0.279782</td>\n",
       "      <td>0.261775</td>\n",
       "      <td>-5.199297</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>rb-lora-1.18M</td>\n",
       "      <td>0.914393</td>\n",
       "      <td>0.871336</td>\n",
       "      <td>0.279782</td>\n",
       "      <td>0.334828</td>\n",
       "      <td>16.940629</td>\n",
       "      <td>1.602405e-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>rb-adapter-895K</td>\n",
       "      <td>0.914393</td>\n",
       "      <td>0.882974</td>\n",
       "      <td>0.279782</td>\n",
       "      <td>0.321452</td>\n",
       "      <td>12.656969</td>\n",
       "      <td>5.714049e-37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_A          model_B    mean_A    mean_B     std_A     std_B   \n",
       "0  rb-plain        t5b-plain  0.914393  0.897258  0.279782  0.303621  \\\n",
       "1  rb-plain         rl-plain  0.914393  0.925998  0.279782  0.261775   \n",
       "2  rb-plain    rb-lora-1.18M  0.914393  0.871336  0.279782  0.334828   \n",
       "3  rb-plain  rb-adapter-895K  0.914393  0.882974  0.279782  0.321452   \n",
       "\n",
       "      t_stat         p_val  \n",
       "0   7.124641  5.277183e-13  \n",
       "1  -5.199297  9.999999e-01  \n",
       "2  16.940629  1.602405e-64  \n",
       "3  12.656969  5.714049e-37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tests needed to conduct over these runs and models \n",
    "\n",
    "stats_dict = ddict(list)\n",
    "\n",
    "for model in models:\n",
    "    model_B = model\n",
    "    pred_A =  list(nli_dict[dataset][model_A]['predictions'])\n",
    "    gold_A =  list(nli_dict[dataset][model_A]['label'])\n",
    "    pred_B =  list(nli_dict[dataset][model_B]['predictions'])\n",
    "    gold_B =  list(nli_dict[dataset][model_B]['label'])\n",
    "    \n",
    "    \n",
    "    pred_A = [1 if pred_A[i] == gold_A[i] else 0 for i in range(len(pred_A))]\n",
    "    pred_B = [1 if pred_B[i] == gold_B[i] else 0 for i in range(len(pred_B))]\n",
    "    \n",
    "    stats_dict['model_A'].append(model_A)\n",
    "    stats_dict['model_B'].append(model_B)\n",
    "    stats_dict['mean_A'].append(np.mean(pred_A))\n",
    "    stats_dict['mean_B'].append(np.mean(pred_B))\n",
    "    stats_dict['std_A'].append(np.std(pred_A))\n",
    "    stats_dict['std_B'].append(np.std(pred_B))\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(pred_A, pred_B, alternative='greater')\n",
    "    \n",
    "    stats_dict['t_stat'].append(t_stat)\n",
    "    stats_dict['p_val'].append(p_val)\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame(stats_dict)\n",
    "display(stats_df)    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "def paired_sign_test(a, b):\n",
    "    # Calculate differences\n",
    "    differences = [after - before for after, before in zip(a, b)]\n",
    "\n",
    "    # Count positive and negative differences\n",
    "    positive_count = sum(diff > 0 for diff in differences)\n",
    "    negative_count = sum(diff < 0 for diff in differences)\n",
    "    \n",
    "    # Total number of observations\n",
    "    n = len(differences)\n",
    "    \n",
    "    zeros = n - positive_count - negative_count\n",
    "    \n",
    "    if zeros %2 == 1:\n",
    "        zeros = zeros - 1\n",
    "            \n",
    "    positive_count += zeros // 2\n",
    "    negative_count += zeros // 2\n",
    "\n",
    "    # Calculate p-value using the binomial distribution\n",
    "    k = positive_count\n",
    "    \n",
    "    p_value = binom.sf(positive_count - 1, n, 0.5)  # One-tailed test (greater)\n",
    "\n",
    "\n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bootstrap test computation\n",
    "import random\n",
    "\n",
    "def compute_bootstrapped_df(a, b, num_iter = 1000):\n",
    "    \n",
    "    assert len(a) == len(b)\n",
    "    \n",
    "    a_acc = np.mean(a)\n",
    "    b_acc = np.mean(b)\n",
    "        \n",
    "    sys_diff = a_acc - b_acc\n",
    "        \n",
    "    assert sys_diff >= 0\n",
    "    \n",
    "    idx_list = list(range(len(a)))\n",
    "    cnt      = 0\n",
    "    for i in range(0, num_iter):\n",
    "        random.seed(i)\n",
    "        np.random.seed(i)\n",
    "        curr_idx_list = random.choices(idx_list, k=min(int(0.1*len(idx_list)), 1000))\n",
    "        \n",
    "        a1_acc = np.mean(np.take(a, curr_idx_list))\n",
    "        b1_acc = np.mean(np.take(b, curr_idx_list))\n",
    "    \n",
    "        # comes from the 2012 non-paramteric method of boostrap significance testing\n",
    "        curr_diff = a1_acc - b1_acc\n",
    "        if curr_diff > 2*sys_diff:\n",
    "            cnt += 1\n",
    "    \n",
    "    \n",
    "    p_val = cnt/num_iter\n",
    "\n",
    "    return p_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_A</th>\n",
       "      <th>model_B</th>\n",
       "      <th>mean_A</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>std_A</th>\n",
       "      <th>std_B</th>\n",
       "      <th>sig_test</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>t5b-plain</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.304</td>\n",
       "      <td>sign-test</td>\n",
       "      <td>1.694631e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>t5b-plain</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.304</td>\n",
       "      <td>wilcoxon</td>\n",
       "      <td>1.203107e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>t5b-plain</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.304</td>\n",
       "      <td>ttest-rel</td>\n",
       "      <td>1.020269e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>t5b-plain</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.304</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>1.600000e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_A    model_B  mean_A  mean_B  std_A  std_B   sig_test         p_val\n",
       "0  rb-plain  t5b-plain   0.914   0.897   0.28  0.304  sign-test  1.694631e-03\n",
       "1  rb-plain  t5b-plain   0.914   0.897   0.28  0.304   wilcoxon  1.203107e-32\n",
       "2  rb-plain  t5b-plain   0.914   0.897   0.28  0.304  ttest-rel  1.020269e-32\n",
       "3  rb-plain  t5b-plain   0.914   0.897   0.28  0.304  bootstrap  1.600000e-02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats_dict = ddict(list)\n",
    "\n",
    "sig_tests = [ 'sign-test', 'wilcoxon', 'ttest-rel', 'bootstrap']\n",
    "\n",
    "model_A = 'rb-plain'\n",
    "model_B = 't5b-plain'\n",
    "\n",
    "for sig_test in sig_tests:\n",
    "    \n",
    "    pred_A =  list(nli_dict[dataset][model_A]['predictions'])\n",
    "    gold_A =  list(nli_dict[dataset][model_A]['label'])\n",
    "    pred_B =  list(nli_dict[dataset][model_B]['predictions'])\n",
    "    gold_B =  list(nli_dict[dataset][model_B]['label'])\n",
    "    \n",
    "    \n",
    "    pred_A = [1 if pred_A[i] == gold_A[i] else 0 for i in range(len(pred_A))]\n",
    "    pred_B = [1 if pred_B[i] == gold_B[i] else 0 for i in range(len(pred_B))]\n",
    "    \n",
    "    \n",
    "    stats_dict['model_A'].append(model_A)\n",
    "    stats_dict['model_B'].append(model_B)\n",
    "    stats_dict['mean_A'].append(round(np.mean(pred_A),3))\n",
    "    stats_dict['mean_B'].append(round(np.mean(pred_B),3))\n",
    "    stats_dict['std_A'].append(round(np.std(pred_A),3))\n",
    "    stats_dict['std_B'].append(round(np.std(pred_B),3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if sig_test == 'ttest-rel':\n",
    "        t_stat, p_val = stats.ttest_rel(pred_A, pred_B, alternative='greater')\n",
    "    elif sig_test == 'wilcoxon':\n",
    "        res = stats.wilcoxon(pred_A, pred_B, alternative='greater')\n",
    "        t_stat, p_val = res.statistic, res.pvalue\n",
    "    elif sig_test == 'sign-test':\n",
    "        p_val = paired_sign_test(pred_A, pred_B)\n",
    "    \n",
    "    elif sig_test == 'bootstrap':\n",
    "        p_val = compute_bootstrapped_df(pred_A, pred_B)    \n",
    "\n",
    "        \n",
    "    stats_dict['sig_test'].append(sig_test)\n",
    "    # stats_dict['t_stat'].append(round(t_stat,3))\n",
    "    stats_dict['p_val'].append(p_val)\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame(stats_dict)\n",
    "display(stats_df)    \n",
    "stats_df.to_csv('snli_ttest_rel.csv', index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_A</th>\n",
       "      <th>model_B</th>\n",
       "      <th>mean_A</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>std_A</th>\n",
       "      <th>std_B</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>t5b-plain</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.304</td>\n",
       "      <td>11.869</td>\n",
       "      <td>1.020269e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>rl-plain</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-9.006</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>rb-lora-1.18M</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.335</td>\n",
       "      <td>25.368</td>\n",
       "      <td>9.265626e-141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rb-plain</td>\n",
       "      <td>rb-adapter-895K</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.321</td>\n",
       "      <td>20.691</td>\n",
       "      <td>9.883325e-95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_A          model_B  mean_A  mean_B  std_A  std_B  t_stat   \n",
       "0  rb-plain        t5b-plain   0.914   0.897   0.28  0.304  11.869  \\\n",
       "1  rb-plain         rl-plain   0.914   0.926   0.28  0.262  -9.006   \n",
       "2  rb-plain    rb-lora-1.18M   0.914   0.871   0.28  0.335  25.368   \n",
       "3  rb-plain  rb-adapter-895K   0.914   0.883   0.28  0.321  20.691   \n",
       "\n",
       "           p_val  \n",
       "0   1.020269e-32  \n",
       "1   1.000000e+00  \n",
       "2  9.265626e-141  \n",
       "3   9.883325e-95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ttest - rel \n",
    "\n",
    "stats_dict = ddict(list)\n",
    "\n",
    "for model in models:\n",
    "    model_B = model\n",
    "    pred_A =  list(nli_dict[dataset][model_A]['predictions'])\n",
    "    gold_A =  list(nli_dict[dataset][model_A]['label'])\n",
    "    pred_B =  list(nli_dict[dataset][model_B]['predictions'])\n",
    "    gold_B =  list(nli_dict[dataset][model_B]['label'])\n",
    "    \n",
    "    \n",
    "    pred_A = [1 if pred_A[i] == gold_A[i] else 0 for i in range(len(pred_A))]\n",
    "    pred_B = [1 if pred_B[i] == gold_B[i] else 0 for i in range(len(pred_B))]\n",
    "    \n",
    "    stats_dict['model_A'].append(model_A)\n",
    "    stats_dict['model_B'].append(model_B)\n",
    "    stats_dict['mean_A'].append(round(np.mean(pred_A),3))\n",
    "    stats_dict['mean_B'].append(round(np.mean(pred_B),3))\n",
    "    stats_dict['std_A'].append(round(np.std(pred_A),3))\n",
    "    stats_dict['std_B'].append(round(np.std(pred_B),3))\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_rel(pred_A, pred_B, alternative='greater')\n",
    "    \n",
    "    stats_dict['t_stat'].append(round(t_stat,3))\n",
    "    stats_dict['p_val'].append(p_val)\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame(stats_dict)\n",
    "display(stats_df)    \n",
    "stats_df.to_csv('snli_ttest_rel.csv', index=False)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval)\n",
      "Comparison  Statistic  p-value  Lower CI  Upper CI\n",
      " (0 - 1)      0.017     0.000     0.010     0.024\n",
      " (0 - 2)     -0.012     0.000    -0.018    -0.005\n",
      " (0 - 3)      0.043     0.000     0.036     0.050\n",
      " (0 - 4)      0.031     0.000     0.025     0.038\n",
      " (1 - 0)     -0.017     0.000    -0.024    -0.010\n",
      " (1 - 2)     -0.029     0.000    -0.036    -0.022\n",
      " (1 - 3)      0.026     0.000     0.019     0.033\n",
      " (1 - 4)      0.014     0.000     0.008     0.021\n",
      " (2 - 0)      0.012     0.000     0.005     0.018\n",
      " (2 - 1)      0.029     0.000     0.022     0.036\n",
      " (2 - 3)      0.055     0.000     0.048     0.061\n",
      " (2 - 4)      0.043     0.000     0.036     0.050\n",
      " (3 - 0)     -0.043     0.000    -0.050    -0.036\n",
      " (3 - 1)     -0.026     0.000    -0.033    -0.019\n",
      " (3 - 2)     -0.055     0.000    -0.061    -0.048\n",
      " (3 - 4)     -0.012     0.000    -0.018    -0.005\n",
      " (4 - 0)     -0.031     0.000    -0.038    -0.025\n",
      " (4 - 1)     -0.014     0.000    -0.021    -0.008\n",
      " (4 - 2)     -0.043     0.000    -0.050    -0.036\n",
      " (4 - 3)      0.012     0.000     0.005     0.018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the tukey HSD test for the 5 systems of comparison\n",
    "\n",
    "models = ['rb-plain', 't5b-plain', 'rl-plain',  'rb-lora-1.18M', 'rb-adapter-895K']\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for model in models:\n",
    "    pred_A =  list(nli_dict[dataset][model]['predictions'])\n",
    "    gold_A =  list(nli_dict[dataset][model]['label'])\n",
    "    pred_A = [1 if pred_A[i] == gold_A[i] else 0 for i in range(len(pred_A))]\n",
    "    predictions.append(pred_A)\n",
    "    \n",
    "\n",
    "res = stats.tukey_hsd(predictions[0], predictions[1], predictions[2], predictions[3], predictions[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['premise', 'hypothesis', 'label', 'predictions', 'seed', 't5b-plain'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_dict['snli']['t5b-plain'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SICON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
