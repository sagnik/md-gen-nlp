{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ae3b13",
   "metadata": {},
   "source": [
    "## Login to HF_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6435e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/varu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\") # HF write token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9bcf9",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7566f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import collections\n",
    "import random\n",
    "\n",
    "def filter_out_yes_no_answers(sample):\n",
    "    return sample['answer'].lower() != 'yes' and sample['answer'].lower() != 'no'\n",
    "    \n",
    "def filter_function(examples):\n",
    "    question = examples[\"question\"]\n",
    "    context = examples[\"context\"]\n",
    "    input_len = len(tokenizer(question,context, truncation=False).input_ids)\n",
    "    return (input_len < tokenizer.model_max_length)\n",
    "\n",
    "def advhotpotqa2squad(sample):\n",
    "    supporting_facts = sample['supporting_facts']\n",
    "    context_texts = sample['context']\n",
    "    titles_to_sentences = collections.defaultdict(list)\n",
    "\n",
    "    for title,sentence in zip(context_texts['title'],context_texts['sentences']):\n",
    "        for s in sentence:\n",
    "            text = s.strip()\n",
    "            titles_to_sentences[title].append(text)\n",
    "\n",
    "    sf_titles = supporting_facts['title']\n",
    "    sf_sent_id = supporting_facts['sent_id']\n",
    "\n",
    "    sf_context=[]\n",
    "    for i,sf_title in enumerate(sf_titles):\n",
    "        try:\n",
    "            text = titles_to_sentences[sf_title][sf_sent_id[i]]\n",
    "        except:\n",
    "            sample['_id'] = 'skip'\n",
    "        sf_context.append(text.strip())\n",
    "\n",
    "    sample['id'] = sample['_id']\n",
    "    # ---Shuffle sentences in context and join them into a single string ---#\n",
    "    context_list = sf_context + titles_to_sentences['added']\n",
    "    random.shuffle(context_list)\n",
    "    sample['context'] = ' '.join(context_list)\n",
    "    sample['answers'] = {'text':[sample['answer']], 'answer_start':[sample['context'].find(sample['answer'])]}\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8183f232",
   "metadata": {},
   "source": [
    "## Truncate dataset and push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = ['squad', 'sagnikrayc/adversarial_hotpotqa']\n",
    "tokenizer_list = ['bert-base-cased', 'roberta-base', 't5-base']\n",
    "org_name = 'varun-v-rao/'\n",
    "\n",
    "for dataset_str in dataset_list:\n",
    "    dataset_name = dataset_str.split('/')[-1]\n",
    "    hf_hub_id = org_name + dataset_name \n",
    "    \n",
    "    print(f\"### Truncating {dataset_name} dataset ###\")\n",
    "    dataset = load_dataset(dataset_str)\n",
    "    \n",
    "    if dataset_str == 'sagnikrayc/adversarial_hotpotqa':\n",
    "        print(\"\\t---> Filtering out 'yes' and 'no' answers for adv. hotpotqa\")\n",
    "        dataset = dataset.filter(filter_out_yes_no_answers, num_proc=4)\n",
    "        print(\"\\t---> Converting Adv_HotPotQA to Squad format\")\n",
    "        dataset = dataset.map(advhotpotqa2squad, num_proc=4, remove_columns=[\"type\",'level','supporting_facts','answer','_id']).filter(lambda x: x['id']!='skip')\n",
    "\n",
    "    for model_checkpoint in tokenizer_list:\n",
    "        print(f\"\\t---> Filtering dataset using {model_checkpoint} tokenizer\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "        dataset = dataset.filter(filter_function)\n",
    "    \n",
    "    print(\"\\t---> Pushing dataset to hub\")\n",
    "    dataset.push_to_hub(hf_hub_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb3a1f",
   "metadata": {},
   "source": [
    "## Loading dataset from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52feb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbd3e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c483a9e2594f4881d332649aace9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/611 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8be3881ce849dd80bce0b54a7589b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be568382202403ab123b76805339b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/16.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbab772360643a9bfafa9e44fbcc5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1efaeabda4d4a909360d6b11b8a6393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83adaa59ed1e43bd846b3aae58cab607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/33634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ebc4fcfa27483eb712101fee611f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"varun-v-rao/adversarial_hotpotqa\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08d0f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20c2935e3e14359bb82a5593bd1f9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/643 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8334f9d7bc6242a289d74b6d3423c226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d40d80f457d4ee58feb63603190ea10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3865919a334c98871fe5950fdb93ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e87a0bf6d1242e2b6b0a076d09a5ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e64c67b246e460cae06cd48c37896d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b528cf86cbb499ba625ac87f3e470c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"varun-v-rao/squad\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05331671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "print(datasets.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
